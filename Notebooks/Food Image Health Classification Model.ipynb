{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f433dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ColorJitter(brightness=0.1,contrast=0.1,saturation=0.1),\n",
    "        torchvision.transforms.RandomAffine(15),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.RandomRotation(15),\n",
    "        torchvision.transforms.Resize((224,224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "valid_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((64, 64)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_path = 'Downloads/archive/food41/images/'\n",
    "train_dataset = torchvision.datasets.ImageFolder(root = image_file_path, transform = train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b71ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_transform_images(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset,batch_size = 6,shuffle=True)\n",
    "    batch = next(iter(loader))\n",
    "    images, labels = batch\n",
    "    grid = torchvision.utils.make_grid(images,nrow = 1)\n",
    "    plt.figure(figsize=(11,11))\n",
    "    plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "    print('labels:',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db42632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_len = round(len(train_dataset )* 0.75)\n",
    "test_len = round(len(train_dataset)* 0.25)\n",
    "\n",
    "\n",
    "train_data, test_data = random_split(train_dataset, [train_len, test_len])\n",
    "\n",
    "print(\"The length of train data is:\",len(train_data))\n",
    "\n",
    "print(\"The length of test data is:\",len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b633cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(dict(Counter(train_dataset.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a383e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "y_train_indices = train_data.indices\n",
    "\n",
    "y_train = [train_dataset.targets[i] for i in y_train_indices]\n",
    "\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(y_train == t)[0]) for t in np.unique(y_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in y_train])\n",
    "samples_weight = torch.from_numpy(samples_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=128, sampler=sampler)\n",
    "test_dataloader = DataLoader(test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        dev=\"cuda:0\"\n",
    "    else:\n",
    "        dev=\"cpu\"\n",
    "    return torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14491925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, train_loader, test_loader, criterion, optimizer, n_epochs):\n",
    "    device = set_device()\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch number: {epoch + 1}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        total = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            images,labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            total+=labels.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            _,predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            loss = criterion(outputs,labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            running_correct += (labels == predicted).sum().item()\n",
    "            \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100.00 * (running_correct/total)\n",
    "        \n",
    "        print(f\"    - Training dataset. Got {running_correct} out of {total} images correctly {epoch_acc}%. Epoch loss {epoch_loss}\")\n",
    "        \n",
    "        evaluate_model_on_test_set(model, test_dataloader)\n",
    "        \n",
    "    print(\"Finished\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test_set(model, test_loader):\n",
    "    model.eval()\n",
    "    predicted_correctly_on_epoch = 0\n",
    "    total = 0\n",
    "    device = set_device()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            predicted_correctly_on_epoch += (predicted == labels).sum().item()\n",
    "            \n",
    "    epoch_acc = 100.0 * predicted_correctly_on_epoch / total\n",
    "    print(f\" - Testing dataset Got {predicted_correctly_on_epoch} out of {total} images correct. {epoch_acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c6e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import urllib.request\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "resnet18_model = models.resnet18(pretrained=False)\n",
    "num_ftrs = resnet18_model.fc.in_features\n",
    "number_of_classes = 4\n",
    "resnet18_model.fc = nn.Linear(num_ftrs,number_of_classes)\n",
    "device = set_device()\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(resnet18_model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 0.003)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb5ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nn(resnet18_model, train_dataloader, test_dataloader, loss_fn, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resnet18_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2682fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'resnet18_torch_trained_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(resnet18_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407154aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb337db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def pre_image(image_path,model):\n",
    "   img = Image.open(image_path)\n",
    "   mean = [0.485, 0.456, 0.406] \n",
    "   std = [0.229, 0.224, 0.225]\n",
    "   transform_norm = transforms.Compose([transforms.ToTensor(), \n",
    "   transforms.Resize((224,224)),transforms.Normalize(mean, std)])\n",
    "   # get normalized image\n",
    "   img_normalized = transform_norm(img).float()\n",
    "   img_normalized = img_normalized.unsqueeze_(0)\n",
    "   # input = Variable(image_tensor)\n",
    "   img_normalized = img_normalized.to(device)\n",
    "   # print(img_normalized.shape)\n",
    "   with torch.no_grad():\n",
    "      model.eval()  \n",
    "      output = model(img_normalized)\n",
    "     # print(output)\n",
    "      index = output.data.cpu().numpy().argmax()\n",
    "      classes = train_dataset.classes\n",
    "      m = nn.Softmax(dim=1)\n",
    "      results = m(output)\n",
    "      results = sorted(results)\n",
    "      class_name = classes[index]\n",
    "      result_name = f'{class_name}, Confidence Value: {round(torch.max(results[0]).item() * 100, 2)} %'\n",
    "      return result_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55345b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_image('/Users/aadrijupadya/Downloads/test.jpeg', loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be34854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba1f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%history\n",
    "\n",
    "\n",
    "print(str(input[0][1].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d5ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d889e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
